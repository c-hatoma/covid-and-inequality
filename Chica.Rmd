---
title: "Chica"
output: html_notebook
---

## 05/05/20 ----------------------------------------------------------------------
## 05/08/20 ----------------------------------------------------------------------

By Friday: data in order, choose what algorithms to work on
Next week: Work on our algorithms

Options:

* lm [ lm(covid cases ~ ., data = covid.eviction) ]
    supervised
    predictive
    linear
    numeric outcome

* k-means clustering
    unsupervised
    we can visualize clusters of similar data by distance

* knn
    supervised
    predictive
    can predict based on nearest data points (categorial predictor)
    
* decision trees
    supervised & unsupervised
    predictive:
      regression context: predict covid cases using features like eviction
      can use lm or other models as predictors
    classification:
      can just be used to visualize by similar features
    
* random forest
    supervised & unsupervised
    better tree models
    predictive
    classification
    
* lda
    unsupervised
    used for clustering: maxes distance between categories, mins distance within
    mostly just for grouping similar things

* pca
    unsupervised
    transforms data to new coordinate system which maxes variance between classes
    also mostly used just to make data easy to visualize by similarity/difference
    kind of difficult with our data, but we could look at just eviction similarities/differences and how that translates to covid

* splines
    fits a bunch of data with a squiggly line
    requires a more or less clear pattern, right? and continuous data on both axes?

* hierarchical clustering
    

* kernel smoothing
    supervised
    predictive
    estimates function as weighted avg of neighboring data (closer points weighted more)



## Unsupervised:


## Supervised:


## 05/07/20 ----------------------------------------------------------------------

Libraries:
```{r libraries, include=FALSE}
library(readxl)
library(tidyverse)
```

Load in data:
(covid data for 4/30/20)
```{r data, eval=FALSE, include=FALSE}
covid.data <- read.csv("covid_confirmed_usafacts_2.csv")
covid.cases <- covid.data[, c(1:4, 104)]
colnames(covid.cases)[c(1, 2, 5)] <- c("countyFIPS", "County", "covidCases")
```

just in case it's useful I'm gonna bring in death numbers.
```{r, eval=FALSE, include=FALSE}
covid.deaths.data <- read_csv('covid_deaths_usafacts.csv')
covid.deaths <- covid.deaths.data[, c(1:4, 104)]
colnames(covid.deaths)[c(1, 2, 5)] <- c("countyFIPS", "County", "covidDeaths")
```

Pop data we can use to control/adjust covid case and eviction filing rate data.
```{r, eval=FALSE, include=FALSE}
covid.pop.data <- read_csv('covid_county_population_usafacts.csv')
covid.pop <- covid.pop.data
```

combine all of the covid data
```{r, eval=FALSE, include=FALSE}
covid <- full_join(covid.cases, covid.deaths[, c(1, 5)],
                   by = "countyFIPS")

covid <- full_join(covid, covid.pop[, c(1, 4)],
                   by = "countyFIPS")

```

filtering out non-county rows ("Statewide Unallocated")
```{r, eval=FALSE, include=FALSE}
covid <- covid %>%
  filter(countyFIPS != 0)
covid <- covid %>%
  filter(countyFIPS != 1)
```

this is at a bunch of levels but not county I think so I'm going to get something at the county level. that way it can match our county-level covid data.
```{r, eval=FALSE, include=FALSE}
# eviction.data <- read.csv("eviction.csv")
# eviction <- eviction.data
```

this is just the state-reported filing rate for several years. I'll narrow it down to the most recent year.
```{r, include=FALSE}
# eviction.county.data <- read_xlsx('ExtStatsFull.xlsx', sheet = 4)
# eviction <- eviction.county.data
```

Let's see what the most recent year looks like:
```{r, eval=FALSE, include=FALSE}
eviction.2016 <- eviction %>%
  filter(year == 2016)
```

Trying to figure out why there are more rows in covid than in eviction data. I guess we can just go with counties where we have both info for both. This leaves us with 26 states.
```{r, eval=FALSE, include=FALSE}
length(unique(covid$countyFIPS))
length(unique(eviction.2016$fips))
  
covid.eviction <- inner_join(eviction.2016[, c(1, 4, 5)], covid,
          by = c("fips" = "countyFIPS"))
colnames(covid.eviction)[3] <- "Evictions"
```

Create our mean benchmarks for evictions, deaths, and cases, all over pop. 
US total pop taken from https://www.census.gov/popclock/
```{r, eval=FALSE, include=FALSE}
state.mean.evictions <- covid.eviction %>%
  group_by(State) %>%
  summarize(state_mean_filing_rate = mean(as.numeric(`eviction-filing-rate`), na.rm = TRUE))

covid.eviction <- full_join(covid.eviction, state.mean.evictions,
                            by = "State")

covid.eviction  <- covid.eviction %>%
  mutate(evictions_greater_state = ifelse(`eviction-filing-rate` > state_mean_filing_rate,
                                          1,
                                          0))

US.mean.evictions <- covid.eviction %>%
  summarize(US_mean_filing_rate = mean(as.numeric(`eviction-filing-rate`), na.rm = TRUE))

covid.eviction <- covid.eviction %>%
  mutate(US_mean_filing_rate = US.mean.evictions$US_mean_filing_rate)

covid.eviction <- covid.eviction %>%
  mutate(evictions_greater_US = ifelse(`eviction-filing-rate` > US_mean_filing_rate,
                                       1,
                                       0))
```

I'm gonna base covid data on average of all states/counties including those that we don't have evictiond data for.
```{r, eval=FALSE, include=FALSE}
Us.covid.cases.rate <- covid.eviction %>%
  summarize(US_covid_cases_rate = sum(covidCases)/329584132)

covid.eviction <- covid.eviction %>%
  mutate(US_covid_cases_rate = Us.covid.cases.rate$US_covid_cases_rate)

US.covid.death.rate <- covid %>%
  summarize(US_covid_death_rate = sum(covidDeaths)/sum(covidCases))

covid.eviction <- covid.eviction %>%
  mutate(US_covid_death_rate = US.covid.death.rate$US_covid_death_rate)

covid.eviction <- covid.eviction %>%
  mutate(county_covid_cases_rate = covidCases/population)

covid.eviction <- covid.eviction %>%
  mutate(county_covid_death_rate = covidDeaths/covidCases)

State.covid.cases.rate <- covid.eviction %>%
  group_by(State) %>%
  summarize(state_covid_cases_rate = mean(county_covid_cases_rate))

covid.eviction <- full_join(covid.eviction, State.covid.cases.rate,
                            by = "State")

State.covid.death.rate <- covid.eviction %>%
  group_by(State) %>%
  summarize(state_covid_death_rate = mean(county_covid_death_rate))

covid.eviction <- full_join(covid.eviction, State.covid.death.rate,
                            by = "State")
  
covid.eviction <- covid.eviction %>%
  mutate(covidCases_greater_state = ifelse(county_covid_cases_rate > state_covid_cases_rate,
                                           1,
                                           0))

covid.eviction <- covid.eviction %>%
  mutate(covidCases_greater_US = ifelse(county_covid_cases_rate >
                                          US_covid_cases_rate,
                                        1,
                                        0))

covid.eviction <- covid.eviction %>%
  mutate(covidDeaths_greater_US = ifelse(county_covid_death_rate >
                                          US_covid_death_rate,
                                        1,
                                        0))

covid.eviction <- covid.eviction %>%
  mutate(covidDeaths_greater_state = ifelse(county_covid_death_rate >
                                              state_covid_death_rate,
                                            1,
                                            0))
```

Reorganize columns:
```{r, eval=FALSE, include=FALSE}
covid.eviction <- covid.eviction[, c(1:2, 4, 9, 6, 5, 3, 10:11, 14, 12:13, 
                                     7:8, 17:20, 15:16, 21, 24, 22:23)]
```

write new csv:
```{r, eval=FALSE, include=FALSE}
# write_csv(covid.eviction, "covid_eviction.csv")
```

## 05/08/2020 --------------------------------------------------------------------

Add in other evictionlab variables:
```{r}
covid.eviction <- read_csv('covid_eviction.csv')

US.evictions <- read_csv('counties_us.csv')

eviction <- US.evictions

eviction.2016 <- eviction %>%
  filter(year == 2016)

length(unique(covid$countyFIPS))
length(unique(eviction.2016$GEOID))

str(eviction.2016$GEOID)
str(covid$countyFIPS)

eviction.2016$GEOID <- as.numeric(eviction.2016$GEOID)
  
covid.eviction <- inner_join(eviction.2016[, -c(3:5)], covid,
          by = c("GEOID" = "countyFIPS"))

# write_csv(covid.eviction, "covid_eviction2.csv")

```

## 05/14/2020 --------------------------------------------------------------------

# LM
```{r}
library(readxl)
library(tidyverse)
covid.eviction <- read_csv('covid_eviction2.csv')
```

simple lm:
covid case rate against eviction filing rate
```{r}
lm1 <- lm(county_covid_cases_rate ~ `eviction-filing-rate`,
          data = covid.eviction)
summary(lm1)
```
significant
Rsq
What other measures do we need to compare this to other models?

graph it to see what the slope looks like:
```{r}
library(ggplot2)
covid.eviction %>%
  ggplot(aes(x = `eviction-filing-rate`,
             y = county_covid_cases_rate)) +
  geom_point() +
  geom_abline(intercept = 1.121e-03, 
              slope = 9.185e-05)
```

Are there outliers I need to remove?
```{r}
outliers <- boxplot.stats(covid.eviction$`eviction-filing-rate`)$out
```
eh nevermind

Add controls for poverty rate:
```{r}
lm2 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `poverty-rate`,
          data = covid.eviction)
summary(lm2)
```
Adjusted R-sq increased
all variables significant

Try with additional income variables:
```{r}
lm3 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `poverty-rate` + `renter-occupied-households`,
          data = covid.eviction)
summary(lm3)
```
Adjusted R squared just doubled. 
Is renter occupied households just increasing bc its not a rate? (greater pop -> greater renter pop)

Will try control:
```{r}
covid.eviction2 <- covid.eviction %>%
  mutate(renter_rate = `renter-occupied-households`/population)

lm4 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `poverty-rate` + renter_rate,
          data = covid.eviction2)
summary(lm4)
```
decreases Adj r-sq but still higher than simple or just eviction filing and poverty rate lm.  will go with this.

Add more variables:
```{r}
lm5 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `poverty-rate` + renter_rate +
            `rent-burden`,
          data = covid.eviction2)
summary(lm5)
```
Rent burden seems to make poverty rate insignificant. Prob bc they kind of represent the same thing. 
Try taking out poverty rate:
```{r}
lm6 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + renter_rate +
            `rent-burden`,
          data = covid.eviction2)
summary(lm6)
```

Other demo variables pct-af-am:
```{r}
lm7 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + renter_rate + `rent-burden` +
            `pct-af-am`,
          data = covid.eviction2)
summary(lm7)
```
drastically increases adj r-sq, and rent-related variables become insignificant.

Remove those rent variables:

```{r}
lm8 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am`,
          data = covid.eviction2)
summary(lm8)
```
adj R-sq decreases slightly but i think the model is better.

Add all other race-related variables:
```{r}
lm9 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` + `pct-am-ind` + `pct-white` + `pct-asian` + `pct-nh-pi`,
          data = covid.eviction2)
summary(lm9)
```
Adj r-sq goes up but significance changes.

Remove insignificant pct-nh-pi:

```{r}
lm10 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` + `pct-am-ind` + `pct-white` + `pct-asian`,
          data = covid.eviction2)
summary(lm10)
```
All race percentages are significant, but they're also all positive, which means being any race makes for greater covid case rates. Some are higher than others, and mostly follow patterns as predicted. I'm going to try anova to see what it comes with.

ANOVA:
```{r}
aov1 <- aov(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` + `pct-am-ind` + `pct-white` + `pct-asian`,
          data = covid.eviction2)
summary(aov1)
```

remove pct-am-ind:
```{r}
aov2 <- aov(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` + `pct-white` + `pct-asian`,
          data = covid.eviction2)
summary(aov2)
```

remove pct white:

```{r}
aov3 <- aov(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` +  `pct-asian`,
          data = covid.eviction2)
summary(aov3)
```


New long model:
```{r}
lm11 <- lm(county_covid_cases_rate ~ `eviction-filing-rate` + `pct-af-am` + `pct-hispanic` +  `pct-asian`,
          data = covid.eviction2)
summary(lm11)
```
Super high adj-rq (comparatively)
All variables significant, but eviction becomes less significant
shows that race seems to matter more than anything.

Try interaction?
```{r}
aov4 <- aov(county_covid_cases_rate ~ `eviction-filing-rate`*`pct-af-am` + `pct-hispanic` +  `pct-asian`,
          data = covid.eviction2)
summary(aov4)
```

Interaction is significant. Adding it to model:
```{r}
lm12 <- lm(county_covid_cases_rate ~ `eviction-filing-rate`*`pct-af-am` + `pct-hispanic` +  `pct-asian`,
          data = covid.eviction2)
summary(lm12)
```
adj r-sq Increases significantly, all variables highly significant.
Shows that as pct-af-am increases, eviction filing rate matters less.
Magnitude of coefficients:
1) pct-asian
2) eviction-filing-rate
3) pct-af-am
4) pct-hispanic
5) eviction-filing-rate:pct-af-am



# KNN
```{r}
library(class)
eviction.seq <- seq(from = 0, to = 109.16, by = 10)
cases.seq <- seq(from = 0, to = .0625, by = .005)
asian.seq <- seq(from = 0, to = 41.64, by = 4)
afam.seq <- seq(from = 0, to = 85.95, by = 7)
hispanic.seq <- seq(from = 0, to = 98.71, by = 9)

grid1 <- expand.grid(eviction.seq, cases.seq)
grid2 <- expand.grid(eviction.seq, cases.seq, asian.seq, afam.seq, hispanic.seq)
grid3 <- expand.grid(eviction.seq, afam.seq)

knn1 <- knn(na.omit(covid.eviction[, c(11, 21, 37)]), grid3, cl = covid.eviction$county_covid_cases_rate, k = 1)

knn1.k10 <- grid3 %>%
  group_by(Var1, Var2) %>%
  mutate(prediction = knn(Var1, Var2, 3))

knn1.k10 %>%
  ggplot(aes(x = Var1,
             y = Var2)) +
  geom_point(aes(color = factor(prediction)),
             size = 2,
             alpha = 0.3) +
  geom_point(data = covid.eviction,
             mapping = aes(x = `eviction-filing-rate`,
                           y = county_covid_cases_rate),
             size = 3)
```

This grid situation isn't working. trying to use a random subset of original data as test:
```{r}

normalize.function <- function(x){
  (x - min(x))/(max(x) - min(x))
}

covid.eviction2 <- covid.eviction[, c(11, 21, 41)] %>%
  na.omit()
ran <- sample(1:nrow(covid.eviction2), 0.9 * nrow(covid.eviction2))
ce <- data.frame(covid.eviction2[, c(1, 2)])
ce <- ce %>%
  na.omit()
ce.norm <- data.frame(lapply(ce[, c(1:2)], normalize.function))

summary(ce.norm)

ce.train <- ce.norm[ran, ]
ce.test <- ce.norm[-ran, ]

train.cl <- covid.eviction2[ran, 3]
test.cl <- covid.eviction2[-ran, 3]

str(train.cl$covidCases_greater_state)
train.cl$covidCases_greater_state <- as.factor(train.cl$covidCases_greater_state)
unique(train.cl$covidCases_greater_state)
train.cl <- train.cl %>%
  na.omit() %>%
  as.data.frame()

length(ce.train$pct.af.am)
length(ce.train$eviction.filing.rate)
length(train.cl$covidCases_greater_state)

library(dplyr)

knn1 <- knn(train = ce.train, test = ce.test, cl = train.cl$covidCases_greater_state, k = 3)

store <- NULL
accuracy <- NULL

for(k in 1:20){
  
  for(i in 1:nrow(covid.eviction2)){
    
    train <- covid.eviction2[-i,]
    test <- covid.eviction2[i,]
    
    prediction <- knn(train = train %>%
                        select(`pct-af-am`, `eviction-filing-rate`),
                      test = test %>%
                        select(`pct-af-am`, `eviction-filing-rate`),
                      train$covidCases_greater_state,
                      k)
      
    store[i] <- ifelse(prediction == covid.eviction2$covidCases_greater_state[i],
                       1, 
                       0)
    
  }
  
  accuracy[k] <- mean(store)
  
    }

k <- (1:20)

find.k <- data.frame(k, accuracy)
```
Now that I've found accuracies, will try to graph it using best k:

```{r}
find.k %>%
  ggplot(aes(x = k, y = accuracy)) +
  geom_point() +
  geom_line()

# we'll go with k = 5

eviction.seq <- seq(from = 0, to = 109.16, by = 1)
afam.seq <- seq(from = 0, to = 85.95, by = 1)

grid <- expand.grid(eviction.seq, afam.seq)

knn.grid <- grid %>%
  mutate(prediction = knn(train = covid.eviction2 %>%
                            select(`pct-af-am`, `eviction-filing-rate`),
                          test = grid,
                          covid.eviction2$covidCases_greater_state,
                          5))

knn.grid %>%
  ggplot(aes(x = Var1,
             y = Var2)) +
  geom_point(aes(color = factor(prediction)),
             size = 2,
             alpha = 0.1) +
  geom_point(data = covid.eviction2,
             mapping = aes(x = `eviction-filing-rate`,
                           y = `pct-af-am`,
                           color = factor(covidCases_greater_state)),
             size = 3) +
  xlab('County Eviction Filing Rate') +
  ylab('County Percent African American Residents') +
  ggtitle('How well does our KNN model predict county COVID outcomes?') +
  scale_color_discrete(name = "Prediction", labels = c("Greater than State Avg", "Less than State Avg"))
```

Repeat but normalized this time:
```{r}
normalize.function <- function(x){
  (x - min(x))/(max(x) - min(x))
}

covid.eviction2 <- covid.eviction[, c(11, 21, 41)] %>%
  na.omit()
ran <- sample(1:nrow(covid.eviction2), 0.9 * nrow(covid.eviction2))
ce <- data.frame(covid.eviction2[, c(1, 2)])
ce <- ce %>%
  na.omit()
ce.norm <- data.frame(lapply(ce[, c(1:2)], normalize.function))

ce2 <- covid.eviction2
ce2$pct.af.am <- normalize.function(ce2$`pct-af-am`)
ce2$eviction.filing.rate <- normalize.function(ce2$`eviction-filing-rate`)

summary(ce2)

store <- NULL
accuracy <- NULL

for(k in 1:20){
  
  for(i in 1:nrow(ce2)){
    
    train <- ce2[-i,]
    test <- ce2[i,]
    
    prediction <- knn(train = train %>%
                        select(pct.af.am, eviction.filing.rate),
                      test = test %>%
                        select(pct.af.am, eviction.filing.rate),
                      train$covidCases_greater_state,
                      k)
      
    store[i] <- ifelse(prediction == ce2$covidCases_greater_state[i],
                       1, 
                       0)
    
  }
  
  accuracy[k] <- mean(store)
  
    }

k <- (1:20)

find.k <- data.frame(k, accuracy)

find.k %>%
  ggplot(aes(x = k, y = accuracy)) +
  geom_point() +
  geom_line()

#we'll go with k = 7

# normalized grid:

eviction.norm.seq <- seq(from = 0, to = 1, by = .01)
afam.norm.seq <- seq(from = 0, to = 1, by = .01)

norm.grid <- expand.grid(eviction.norm.seq, afam.norm.seq)

colnames(norm.grid)[c(1,2)] <- c('eviction.filing.rate', 'pct.af.am') 

knn.grid <- norm.grid %>%
  mutate(prediction = knn(train = ce2 %>%
                            select(pct.af.am, eviction.filing.rate),
                          test = norm.grid,
                          ce2$covidCases_greater_state,
                          7))

knn.grid %>%
  ggplot(aes(x = eviction.filing.rate,
             y = pct.af.am)) +
  geom_point(aes(color = factor(prediction)),
             size = 2,
             alpha = 0.1) +
  geom_point(data = ce2,
             mapping = aes(x = eviction.filing.rate,
                           y = pct.af.am,
                           color = factor(covidCases_greater_state)),
             size = 3) +
  xlab('County Eviction Filing Rate') +
  ylab('County Percent African American Residents') +
  ggtitle('How well does our KNN model predict county COVID outcomes?') +
  scale_color_discrete(name = "Prediction", labels = c("Greater than State Avg", "Less than State Avg"))
```

Repeat for deaths:
```{r}
covid.eviction3 <- covid.eviction[, c(11, 21, 44)] %>%
  na.omit()
ran <- sample(1:nrow(covid.eviction3), 0.9 * nrow(covid.eviction3))
ce <- data.frame(covid.eviction3[, c(1, 2)])
ce <- ce %>%
  na.omit()
ce.norm <- data.frame(lapply(ce[, c(1:2)], normalize.function))

ce3 <- covid.eviction3
ce3$pct.af.am <- normalize.function(ce3$`pct-af-am`)
ce3$eviction.filing.rate <- normalize.function(ce3$`eviction-filing-rate`)
ce3$covidDeaths_greater_state <- as.factor(ce3$covidDeaths_greater_state)

summary(ce3)

store <- NULL
accuracy <- NULL

for(k in 1:20){
  
  for(i in 1:nrow(ce3)){
    
    train <- ce3[-i,]
    test <- ce3[i,]
    
    prediction <- knn(train = train %>%
                        select(pct.af.am, eviction.filing.rate),
                      test = test %>%
                        select(pct.af.am, eviction.filing.rate),
                      train$covidDeaths_greater_state,
                      k)
      
    store[i] <- ifelse(prediction == ce3$covidDeaths_greater_state[i],
                       1, 
                       0)
    
  }
  
  accuracy[k] <- mean(store)
  
    }

k <- (1:20)

find.k <- data.frame(k, accuracy)

find.k %>%
  ggplot(aes(x = k, y = accuracy)) +
  geom_point() +
  geom_line()

#we'll go with k = 4

# normalized grid:

# eviction.norm.seq <- seq(from = 0, to = 1, by = .01)
# afam.norm.seq <- seq(from = 0, to = 1, by = .01)

# norm.grid <- expand.grid(eviction.norm.seq, afam.norm.seq)
# 
# colnames(norm.grid)[c(1,2)] <- c('eviction.filing.rate', 'pct.af.am') 

knn.grid <- norm.grid %>%
  mutate(prediction = knn(train = ce3 %>%
                            select(pct.af.am, eviction.filing.rate),
                          test = norm.grid,
                          ce3$covidDeaths_greater_state,
                          4))

knn.grid %>%
  ggplot(aes(x = eviction.filing.rate,
             y = pct.af.am)) +
  geom_point(aes(color = factor(prediction)),
             size = 2,
             alpha = 0.1) +
  geom_point(data = ce3,
             mapping = aes(x = eviction.filing.rate,
                           y = pct.af.am,
                           color = factor(covidDeaths_greater_state)),
             size = 3) +
  xlab('County Eviction Filing Rate') +
  ylab('County Percent African American Residents') +
  ggtitle('How well does our KNN model predict county COVID Deaths?') +
  scale_color_discrete(name = "Prediction", labels = c("Greater than State Avg", "Less than State Avg"))
```

```{r}
library(caret)
library(ipred)

ran <- sample(1:nrow(covid.eviction3), 0.9 * nrow(covid.eviction3))

train3 <- covid.eviction3[ran, c(1,2)]
test3 <- covid.eviction3[-ran, c(1,2)]
train.cl <- covid.eviction3[ran, 3]
test.cl <- covid.eviction3[-ran, 3]

test.cl$covidDeaths_greater_state <- as.factor(test.cl$covidDeaths_greater_state)

train3.test <- test3 %>%
  mutate(prediction = knn(train = train3,
                          test = test3,
                          train.cl$covidDeaths_greater_state,
                          4))

str(knn.grid$prediction)
str(test.cl$covidDeaths_greater_state)

confusionMatrix(train3.test$prediction, test.cl$covidDeaths_greater_state)
```

