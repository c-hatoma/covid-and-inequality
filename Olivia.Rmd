---
title: "Single Decision Trees, Bagging, Boosting and Random Forests"
author: "Olivia Jin"
date: "5/16/2020"
output: html_document
---

In this section, I will be comparing 4 different types of models: a single decision tree, bagging, boosting, and random forest. I will train these models on the training data, and will be using the testing data to examine each of their accuracy and Cohen's Kappa. 

### Libraries
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rpart)
library(rattle)
library(ipred)
library(fastAdaboost)
library(randomForest)
library(caret)
```

### Load Data
Loading appended data with COVID-19 and eviction data.
```{r data}

covid.eviction <- read_csv("covid_eviction2.csv")

```


## Create Training and Testing Data
Create two data, one for training the different models and the other for testing the models.
```{r training/testing}
#generate index for training data
index <- sample(nrow(covid.eviction),
                size = nrow(covid.eviction)*0.7,
                replace = FALSE)

#create training data
covid.eviction.train <- covid.eviction[index,]

#create testing data
covid.eviction.test <- covid.eviction[-index,]

```


## Single Decision Trees
Create 4 decision tree models for each of the 4 different outcome variables: covidCases_greater_state, covidCases_greater_US, covidDeaths_greater_state, covidDeaths_greater_US. The following also shows the decision trees generated for each of the models. 
```{r single tree}
#single decision tree model for covidCases_greater_state
tree.case.state <- rpart(
  factor(covidCases_greater_state) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train
)

fancyRpartPlot(tree.case.state)

#single decision tree model for covidCases_greater_US
tree.case.US <- rpart(
  factor(covidCases_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train
)

fancyRpartPlot(tree.case.US)

#single decision tree model for covidDeaths_greater_state
tree.death.state <- rpart(
  factor(covidDeaths_greater_state) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train
)

fancyRpartPlot(tree.death.state)

#single decision tree model for covidDeaths_greater_US
tree.death.US <- rpart(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train
)

tree.death.US

```
The last decision tree model, which uses covidDeaths_greater_US as the outcome, does not create a decision tree; it stops at the root node and does not split further. Below, I try to replicate this model but only using county-level data from a single state to check whether that produces decision trees.

```{r single tree 2}
#single decision tree model of NY
tree.death.US.NY <- rpart(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  subset = State == "NY",
  minsplit = 10
)

fancyRpartPlot(tree.death.US.NY)

#single decision tree model of TX
tree.death.US.TX <- rpart(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  subset = State == "TX",
  minsplit = 10
)

fancyRpartPlot(tree.death.US.TX)

#single decision tree model of WA
tree.death.US.WA <- rpart(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  subset = State == "WA",
  minsplit = 10
)

fancyRpartPlot(tree.death.US.WA)

#single decision tree model of MI
tree.death.US.MI <- rpart(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  subset = State == "MI",
  minsplit = 10
)

fancyRpartPlot(tree.death.US.MI)

```

When using a state-level subset of the data (in this case: NY, TX, WA and MI), the models generate decision trees. It is suggested that when looking at the whole US data, the independent variables are not good predictors of whether then COVID-19 death rate ofa county is greater than the US average, but when looking at the specific states, there are some independent variables that are good predictors of the outcome variable. 


## Bagging
Create 4 bagging models for each of the outcome variables. I use the default number of trees in the built-in bagging model, which is 25 bootstrap replications. Below also shows the out-of-bag estimate of misclassification error.

```{r bagging}
#bagging model for covidCases_greater_state
bagging.case.state <- bagging(
  factor(covidCases_greater_state) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  coob = TRUE
)

bagging.case.state

#bagging model for covidCases_greater_US
bagging.case.US <- bagging(
  factor(covidCases_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  coob = TRUE
)

bagging.case.US

#bagging model for covidDeaths_greater_state
bagging.death.state <- bagging(
  factor(covidDeaths_greater_state) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  coob = TRUE
)

bagging.death.state

#bagging model for covidDeaths_greater_US
bagging.death.US <- bagging(
  factor(covidDeaths_greater_US) ~
    `eviction-filing-rate` +
    `poverty-rate` +
    `pct-renter-occupied` +
    `median-household-income` +
    `pct-white` +
    `pct-af-am` +
    `pct-hispanic` +
    `pct-asian` +
    `population`,
  data = covid.eviction.train,
  coob = TRUE
)

bagging.death.US

```


## Boosting
There are 4 different boosting models for each of the outcome variables. The number of trees is 25, which is the default number for the built-in adaboost function. The outcomes also show the weights of each of the trees.

```{r boosting}
#boosting model for covidCases_greater_state
boosting.case.state <- adaboost(
  covidCases_greater_state ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train),
  nIter = 25
)

boosting.case.state

#boosting model for covidCases_greater_US
boosting.case.US <- adaboost(
  covidCases_greater_US ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train),
  nIter = 25
)

boosting.case.US

#boosting model for covidDeaths_greater_state
boosting.death.state <- adaboost(
  covidDeaths_greater_state ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train),
  nIter = 25
)

boosting.death.state

#boosting model for covidDeaths_greater_US
boosting.death.US <- adaboost(
  covidDeaths_greater_US ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train),
  nIter = 25
)

boosting.death.US

```


## Random Forests
Again, there are 4 different random forest models for each of the outcome variables. The type of random forest is classification, and each model has 500 trees and 3 variables tried at each split. The outcome below shows out-of-bag estimate of error rate and the confusion matrix for each of the models.

```{r random forest}
#random forest model for covidCases_greater_state
rf.case.state <- randomForest(
  factor(covidCases_greater_state) ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train) %>%
    na.omit()
)

rf.case.state

#random forest model for covidCases_greater_US
rf.case.US <- randomForest(
  factor(covidCases_greater_US) ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train) %>%
    na.omit()
)

rf.case.US

#random forest model for covidDeaths_greater_state
rf.death.state <- randomForest(
  factor(covidDeaths_greater_state) ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train) %>%
    na.omit()
)

rf.death.state

#random forest model for covidDeaths_greater_US
rf.death.US <- randomForest(
  factor(covidDeaths_greater_US) ~
    eviction.filing.rate +
    poverty.rate +
    pct.renter.occupied +
    median.household.income +
    pct.white +
    pct.af.am +
    pct.hispanic +
    pct.asian +
    population,
  data = data.frame(covid.eviction.train) %>%
    na.omit()
)

rf.death.US

```


## Test the Models on Testing Data

### Predict outcome on testing data using models
We predict the outcome of each variables for testing data using the models we generated above. 
```{r predict}
#predictions for single decision tree models
tree.case.state.preds <-
  ifelse(predict(tree.case.state, covid.eviction.test)[, 2] > 0.5, 1, 0)
tree.case.US.preds <-
  ifelse(predict(tree.case.US, covid.eviction.test)[, 2] > 0.5, 1, 0)
tree.death.state.preds <-
  ifelse(predict(tree.death.state, covid.eviction.test)[, 2] > 0.5, 1, 0)
tree.death.US.preds <-
  ifelse(predict(tree.death.US, covid.eviction.test)[, 2] > 0.5, 1, 0)

#predictions for bagging models
bagging.case.state.preds <-
  predict(bagging.case.state, covid.eviction.test)
bagging.case.US.preds <-
  predict(bagging.case.US, covid.eviction.test)
bagging.death.state.preds <-
  predict(bagging.death.state, covid.eviction.test)
bagging.death.US.preds <-
  predict(bagging.death.state, covid.eviction.test)

#predictions for boosting models
boosting.case.state.preds <-
  predict(boosting.case.state, data.frame(covid.eviction.test))$class
boosting.case.US.preds <-
  predict(boosting.case.US, data.frame(covid.eviction.test))$class
boosting.death.state.preds <-
  predict(boosting.death.state, data.frame(covid.eviction.test))$class
boosting.death.US.preds <-
  predict(boosting.death.US, data.frame(covid.eviction.test))$class

#predictions for random forest models
rf.case.state.preds <-
  predict(rf.case.state, data.frame(covid.eviction.test))
rf.case.US.preds <-
  predict(rf.case.US, data.frame(covid.eviction.test))
rf.death.state.preds <-
  predict(rf.death.state, data.frame(covid.eviction.test))
rf.death.US.preds <-
  predict(rf.death.US, data.frame(covid.eviction.test))

```


### Function that corrects confusion matrix that is not 2x2
This function corrects confusion matrix that is not 2x2. In the case of our data, the tree.death.US model predicts all the outcomes to be 0, thus the confusion matrix is 1x2. This function corrects it to a 2x2 matrix, so that all confusion matrices would have the same dimensions.
```{r cm correction}
correct.cm <- function(confusion.matrix) {
  #Inputs:
  #confusion.matrix: confusion matrix, ideally 2x2, but could be 1x2 or 2x1
  
  #Output: return a corrected 2x2 confusion matrix as a table
  
  #check if confusion matrix is 2x2
  if (nrow(confusion.matrix) == 2 & ncol(confusion.matrix) == 2) {
    #if 2x2, nothing needs to be corrected
    corrected <- confusion.matrix
   
    #if 1x2 (missing row)
  } else if (nrow(confusion.matrix) == 1) {
    #check the rowname that exists vs missing
    if (rownames(confusion.matrix)[1] == 0) {
      #if outcome == 1 row is missing, add the row (0, 0) to the bottom
      corrected <- rbind(confusion.matrix, c(0, 0))
      rownames(corrected) <- c(0, 1)
      #if outcome == 0 row is missing, add the row (0, 0) to the top
    } else if (rownames(confusion.matrix)[1] == 1) {
      corrected <- rbind(c(0, 0), confusion.matrix)
      rownames(corrected) <- c(0, 1)
    }
    
    #if 2x1 (missing column)
  } else if (ncol(confusion.matrix) == 1) {
    #check the colname that exists vs missing
    if (colnames(confusion.matrix)[1] == 0) {
      #if outcome == 1 col is missing, add the col (0, 0) to the right
      corrected <- cbind(confusion.matrix, c(0, 0))
      colnames(corrected) <- c(0, 1)
      #if outcome == 0 col is missing, add the col (0, 0) to the left
    } else if (colnames(confusion.matrix)[1] == 1) {
      corrected <- cbind(c(0, 0), confusion.matrix)
      colnames(corrected) <- c(0, 1)
    }
  }
 
   #make sure that the final corrected matrix is in a table format
  corrected <- as.table(corrected)
  
  #return corrected 2x2 confusion matrix
  return(corrected)
}

```


### Create confusion matrices for each model
We create confusion matrices for each of the models, and use the function that corrects 1x2 or 2x1 matrices into a 2x2 matrix to make sure that all the matrices are of the same dimesion.
``` {r cm}
#vector of 4 different model types
model.types <- c("tree", "bagging", "boosting", "rf")

#vector of 4 different outcome variables
outcome.vars <-
  c("case.state", "case.US", "death.state", "death.US")

#for loop to generate confusion matrices for each outcome variable using 4 different models 
for (i in model.types) {
  for (j in outcome.vars) {
    
    #creates string variable with the confusion matrix name (eg. "cm.tree.case.state")
    cm <- paste("cm", i, j, sep = ".")
    
    #evaluates the prediction of each model (eg. tree.case.state.preds)
    preds <- eval(parse(text = paste(i, j, "preds", sep = ".")))
    
    #for each outcome variable, it assigns the confusion matrix table to 'cm'
    if (j == "case.state") {
      assign(cm,
             table(preds, covid.eviction.test$covidCases_greater_state))
    } else if (j == "case.US") {
      assign(cm,
             table(preds, covid.eviction.test$covidCases_greater_US))
    } else if (j == "death.state") {
      assign(cm,
             table(preds, covid.eviction.test$covidDeaths_greater_state))
    } else if (j == "death.US") {
      assign(cm,
             table(preds, covid.eviction.test$covidDeaths_greater_US))
    }
    
    #each confusion matrix generated above is corrected to a 2x2 table using the corrected.cm() function
    assign(cm, correct.cm(eval(as.name(cm))))
  }
}


```


# Accuracy Function
This function uses a 2x2 confusion matrix as an input to calculate the accuracy.
```{r accuracy}
accuracy <- function(confusion.matrix) {
  #Inputs:
  #confusion.matrix: confusion matrix of an algorithm (dimensions: 2x2)
  
  #Output: return accuracy
  
  #calculate accuracy (observed agreement)
  accuracy <-
    (confusion.matrix[1, 1] + confusion.matrix[2, 2]) / sum(confusion.matrix)
  
  return(accuracy)
}
```


# Cohen's Kappa Function
This function uses a 2x2 confusion matrix as an input to calculate Cohen's Kappa.
```{r kappa}
kappa <- function(confusion.matrix) {
  #Inputs:
  #confusion.matrix: confusion matrix of an algorithm (dimensions: 2x2)
  
  #Output: return Cohen's kappa
  
  #calculate observed agreement (accuracy)
  Po <-
    (confusion.matrix[1, 1] + confusion.matrix[2, 2]) / sum(confusion.matrix)
  
  #calculate probability of agreement by random chance
  Pe <- 1 / sum(confusion.matrix) ^ 2 *
    (sum(confusion.matrix[1,] * sum(confusion.matrix[, 1])) +
       sum(confusion.matrix[2,] * sum(confusion.matrix[, 2])))
  
  #calculate Cohen's Kappa
  kappa = (Po - Pe) / (1 - Pe)
  
  return(kappa)
}
```


# Create a table to compare all models
We calculate the accuracy and the kappa of each model, and we use that to generate a comparison table that shows the accuracy and the kappa for each type of model for each outcome variable. 
```{r comparison}
#vector of 4 different outcome variables
outcome.vars <- c("case.state", "case.US", "death.state", "death.US")

#null vectors for single decision tree models' accuracy and kappa values
tree.accuracy <- NULL
tree.kappa <- NULL

#vectors for single decision tree models' accuracy values
tree.accuracy <- c(
  accuracy(cm.tree.case.state),
  accuracy(cm.tree.case.US),
  accuracy(cm.tree.death.state),
  accuracy(cm.tree.death.US)
)

#vectors for single decision tree models' kappa values
tree.kappa <- c(
  kappa(cm.tree.case.state),
  kappa(cm.tree.case.US),
  kappa(cm.tree.death.state),
  kappa(cm.tree.death.US)
)

#null vectors for bagging models' accuracy and kappa values
bagging.accuracy <- NULL
bagging.kappa <- NULL

#vectors for bagging models' accuracy values
bagging.accuracy <- c(
  accuracy(cm.bagging.case.state),
  accuracy(cm.bagging.case.US),
  accuracy(cm.bagging.death.state),
  accuracy(cm.bagging.death.US)
)

#vectors for bagging models' kappa values
bagging.kappa <- c(
  kappa(cm.bagging.case.state),
  kappa(cm.bagging.case.US),
  kappa(cm.bagging.death.state),
  kappa(cm.bagging.death.US)
)

#null vectors for boosting models' accuracy and kappa values
boosting.accuracy <- NULL
boosting.kappa <- NULL

#vectors for boosting models' accuracy values
boosting.accuracy <- c(
  accuracy(cm.boosting.case.state),
  accuracy(cm.boosting.case.US),
  accuracy(cm.boosting.death.state),
  accuracy(cm.boosting.death.US)
)

#vectors for boosting models' kappa values
boosting.kappa <- c(
  kappa(cm.boosting.case.state),
  kappa(cm.boosting.case.US),
  kappa(cm.boosting.death.state),
  kappa(cm.boosting.death.US)
)

#null vectors for random forest models' accuracy and kappa values
rf.accuracy <- NULL
rf.kappa <- NULL

#vectors for random forest models' accuracy values
rf.accuracy <- c(
  accuracy(cm.rf.case.state),
  accuracy(cm.rf.case.US),
  accuracy(cm.rf.death.state),
  accuracy(cm.rf.death.US)
)

#vectors for random forest models' kappa values
rf.kappa <- c(
  kappa(cm.rf.case.state),
  kappa(cm.rf.case.US),
  kappa(cm.rf.death.state),
  kappa(cm.rf.death.US)
)

#generate data frame of accuracy and kappa values of each models for different outcome variables
comparison <- data.frame(outcome.vars, tree.accuracy, tree.kappa, bagging.accuracy, bagging.kappa, boosting.accuracy, boosting.kappa, rf.accuracy, rf.kappa)

comparison
```

Looking at the comparison table above, random forest models generally have the highest accuracy and high kappa values. Boostig models have similarly high accuracy rates, but slightly higher kappa values than random forests. Bagging models generally do better than single decision tree models. This is as expected, as decision trees have low bias but high variance. Bagging lowers variance of the models by using multiple decision trees, thus accuracy and kappa of bagging models are generally higher than a single decision tree. On the other hand, boosting reduces bias by training with more weight on misclassified observations. Random forests, similarly to bagging, reduces variance, but it also creates a more robust model by randomizing the subset of variables considered at each split. 

Works Cited:
https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229
https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205
https://towardsdatascience.com/why-random-forest-is-my-favorite-machine-learning-model-b97651fa3706